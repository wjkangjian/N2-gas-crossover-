{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('finaldatabase.csv',encoding=\"utf-8\")\n",
    "raw_data=fdata.loc[:,[                     \n",
    "    'xN2a_in0',#0\n",
    "    'RH_CC',#1\n",
    "    'dela_CH (mm)',#2\n",
    "    'dela_M (um)',#3\n",
    "    'dela_GDL (um)',#4\n",
    "    'p_A (atm)',#5\n",
    "    'T_cc (K)',#6\n",
    "    'E cell (V)',#7\n",
    "    'current',#8\n",
    "    'fyN2',#9\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "standardized_data = (raw_data-np.mean(raw_data,axis=0))/np.std(raw_data,axis=0)\n",
    "raw_input=raw_data.iloc[:,0:8]\n",
    "raw_output=raw_data.iloc[:,9]*1e15\n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_input, raw_output, test_size=.15,random_state=seed)\n",
    "y_test_values=y_test.values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ada_model=joblib.load('ada_model')\n",
    "algorithm_name='AdaBoost'\n",
    "result = ada_model.predict(X_test)\n",
    "x_prediction=result\n",
    "y_real=y_test_values\n",
    "x_prediction_series=pd.Series(x_prediction)\n",
    "y_real_series=pd.Series(y_real)\n",
    "###########evaluating the regression quality##########\n",
    "\n",
    "rmse_val= rmse(x_prediction,y_real)\n",
    "r2_score_current=r2_score(x_prediction,y_real)\n",
    "print('可决系数 r2_score_current: ',r2_score_current)\n",
    "print('方差 rmse_val：',rmse_val)\n",
    "\n",
    "###########generating a figure##########\n",
    "x_y_x=np.arange(2,8,0.1)\n",
    "x_y_y=np.arange(2,8,0.1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(x_prediction,y_real,edgecolor='black',s=10,label=algorithm_name)\n",
    "ax.plot(x_y_x,x_y_y)\n",
    "plt.legend()\n",
    "plt.xlabel(u\"predict crossover rate ×10^15 mol/m/s/pa\")\n",
    "plt.ylabel(u\"real predict crossover rate ×10^15 mol/m/s/pa\")\n",
    "plt.savefig('%s Crossover rate Regression.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "name_list=list(X_test)\n",
    "plt.bar(range(len(ada_model.feature_importances_)), ada_model.feature_importances_,edgecolor='black',tick_label=name_list)\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('%s FeatureImportance.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print(ada_model.feature_importances_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##shapvalues caculation\n",
    "\n",
    "explainer=shap.Explainer(ada_model)\n",
    "shapvalues=explainer(X_test)\n",
    "shap_values=explainer.shap_values(X_test)\n",
    "shap_interaction_values = explainer.shap_interaction_values(X_test)\n",
    "expected_value = explainer.expected_value\n",
    "explainer2 = shap.Explainer(ada_model,X_test)\n",
    "shap_values2 = explainer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "##bar plot\n",
    "shap.plots.bar(shapvalues[0],max_display=10,show=False)\n",
    "plt.savefig('%s shapvalues_distribution_single.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##bar plot\n",
    "shap.plots.bar(shapvalues,max_display=10,show=False)\n",
    "plt.savefig('%s shapvalues_distribution.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print(name_list)\n",
    "print(shapvalues.abs.mean(0).values)\n",
    "\n",
    "##bar plot   optimally separate the SHAP values of the instances using a sklearn DecisionTreeRegressor. \n",
    "## 2 \n",
    "shap.plots.bar(shapvalues.cohorts(2).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution2.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##bar plot   optimally separate the SHAP values of the instances using a sklearn DecisionTreeRegressor. \n",
    "## 3 \n",
    "shap.plots.bar(shapvalues.cohorts(3).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution3.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##bar plot   optimally separate the SHAP values of the instances using a sklearn DecisionTreeRegressor. \n",
    "## 4 \n",
    "shap.plots.bar(shapvalues.cohorts(4).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution4.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##bar plot   optimally separate the SHAP values of the instances using a sklearn DecisionTreeRegressor. \n",
    "## 5 \n",
    "shap.plots.bar(shapvalues.cohorts(5).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution5.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##high low feature imortance distribution\n",
    "j=0\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 0.35 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=1\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 0.5 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=2\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 1.5 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=3\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 250 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=4\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 250 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=5\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 3 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=6\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 340 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "j=7\n",
    "ka = [\"low {}\".format(name_list[j]) if shapvalues.data[i,j] <= 0.6 else \"high {}\".format(name_list[j]) for i in range(shapvalues.shape[0])]\n",
    "shap.plots.bar(shapvalues.cohorts(ka).abs.mean(0),show=False)\n",
    "plt.savefig('%s shapvalues_distribution{}.jpg'.format(name_list[j]) %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##heatmap\n",
    "shap.plots.heatmap(shapvalues[:1000],show=False)\n",
    "plt.savefig('%s shapvalues_heatmap.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "shap.plots.heatmap(shapvalues[:1000], feature_values=shapvalues.abs.max(0),show=False)\n",
    "plt.savefig('%s shapvalues_heatmap_orderby_max.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "#order by sum shapvalues\n",
    "shap.plots.heatmap(shapvalues[:1000], instance_order=shapvalues.sum(1)[:1000],show=False)\n",
    "plt.savefig('%s shapvalues_heatmap_orderby_sum.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##decision plot\n",
    "shap.decision_plot(expected_value, shap_values[:10], X_test,show=False,highlight=0)\n",
    "plt.savefig('%s decision_plot10.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "##decision plot\n",
    "shap.decision_plot(expected_value, shap_values[0], X_test,show=False,highlight=0)\n",
    "plt.savefig('%s decision_plot10_0.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(list(X_test))):\n",
    "    shap.dependence_plot(\"%s\"%list(X_test)[i], shap_values[:2000], X_test[:2000],show=False)\n",
    "    plt.savefig('%s dependence_plot_%s.jpg' %(algorithm_name,list(X_test)[i]),bbox_inches = 'tight')\n",
    "\n",
    "    \n",
    "shap.plots.beeswarm(shap_values2.abs, color=\"shap_red\",show=False)\n",
    "plt.savefig('%s beenswarm_abs.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "## summarize the effects of all the features\n",
    "shap.summary_plot(shap_values[:500], X_test[:500],show=False)\n",
    "plt.savefig('%s feature_effect.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "shap.plots.beeswarm(shap_values2.abs, color=\"shap_red\",show=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "##identify typical prediction pahths\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "T = X_test[(y_pred >= 0)&(y_pred <= 2.5)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "T = X_test[(y_pred >= 3)&(y_pred <= 3.1)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "T = X_test[(y_pred >= 4)&(y_pred <= 4.1)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "T = X_test[(y_pred >= 5)&(y_pred <= 5.1)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "T = X_test[(y_pred >= 6)&(y_pred <= 6.1)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "T = X_test[(y_pred >= 7)&(y_pred <= 7.1)]\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    sh = explainer.shap_values(T)[:500]\n",
    "shap.decision_plot(expected_value, sh, T, feature_order='hclust',show=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('%s tupical_prediction_path500.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    ##shap_interaction_values\n",
    "    shap.decision_plot(expected_value, shap_interaction_values[:10], X_test[:10],show=False)\n",
    "    plt.savefig('%s decision_plot10_interactionvalues.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "    shap.decision_plot(expected_value, shap_interaction_values[:10], X_test[:10],show=False,feature_display_range=slice(None, None, -1))\n",
    "    plt.savefig('%s decision_plot10_interactionvalues_long.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "    shap.decision_plot(expected_value, shap_interaction_values[:1], X_test[:1],show=False,highlight=0)\n",
    "    plt.savefig('%s decision_plot10_interactionvalues_0.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "    shap.summary_plot(shap_interaction_values[:1000], X_test[:1000],show=False)\n",
    "    plt.savefig('%s effect_betweenfeatures.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    for i in range(len(name_list)):\n",
    "        for j in range(len(name_list)):\n",
    "            shap.dependence_plot(\n",
    "                (name_list[i], name_list[j]),\n",
    "                shap_interaction_values, X_test,\n",
    "                show=False\n",
    "\n",
    "            )\n",
    "            plt.savefig('%s dependence_interactionplot_%s%s.jpg' %(algorithm_name,list(X_test)[i],name_list[j]),bbox_inches = 'tight')\n",
    "\n",
    "\n",
    "\n",
    "    import matplotlib.pylab as pl\n",
    "    import numpy as np\n",
    "\n",
    "    tmp = np.abs(shap_interaction_values).sum(0)\n",
    "\n",
    "    for i in range(tmp.shape[0]):\n",
    "        tmp[i,i] = 0\n",
    "    inds = np.argsort(-tmp.sum(0))[:50]\n",
    "    tmp2 = tmp[inds,:][:,inds]\n",
    "    pl.figure(figsize=(8,8))\n",
    "    pl.imshow(tmp2)\n",
    "    pl.yticks(range(tmp2.shape[0]), X_test.columns[inds], rotation=50.4, horizontalalignment=\"right\")\n",
    "    pl.xticks(range(tmp2.shape[0]), X_test.columns[inds], rotation=50.4, horizontalalignment=\"left\")\n",
    "    pl.gca().xaxis.tick_top()\n",
    "    pl.show()\n",
    "    \n",
    "except:\n",
    "    print('shap_interaction_values is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "import shap\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "%matplotlib inline\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('finaldatabase.csv',encoding=\"utf-8\")\n",
    "raw_data=fdata.loc[:,[                     \n",
    "    'xN2a_in0',#0\n",
    "    'RH_CC',#1\n",
    "    'dela_CH (mm)',#2\n",
    "    'dela_M (um)',#3\n",
    "    'dela_GDL (um)',#4\n",
    "    'p_A (atm)',#5\n",
    "    'T_cc (K)',#6\n",
    "    'E cell (V)',#7\n",
    "    'current',#8\n",
    "    'fyN2',#9\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "standardized_data = (raw_data-np.mean(raw_data,axis=0))/np.std(raw_data,axis=0)\n",
    "raw_input=raw_data.iloc[:,0:8]\n",
    "raw_output=raw_data.iloc[:,9]*1e15\n",
    "###########fix random seed for reproducability##########\n",
    "seed=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_input, raw_output, test_size=.15,random_state=seed)\n",
    "y_test_values=y_test.values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ada_model=joblib.load('ada_model')\n",
    "algorithm_name='RandomForest'\n",
    "result = ada_model.predict(X_test)\n",
    "x_prediction=result\n",
    "y_real=y_test_values\n",
    "x_prediction_series=pd.Series(x_prediction)\n",
    "y_real_series=pd.Series(y_real)\n",
    "###########evaluating the regression quality##########\n",
    "\n",
    "rmse_val= rmse(x_prediction,y_real)\n",
    "r2_score_current=r2_score(x_prediction,y_real)\n",
    "print('可决系数 r2_score_current: ',r2_score_current)\n",
    "print('方差 rmse_val：',rmse_val)\n",
    "\n",
    "###########generating a figure##########\n",
    "x_y_x=np.arange(2,8,0.1)\n",
    "x_y_y=np.arange(2,8,0.1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(x_prediction,y_real,edgecolor='black',s=10,label=algorithm_name)\n",
    "ax.plot(x_y_x,x_y_y)\n",
    "plt.legend()\n",
    "plt.xlabel(u\"predict current A/cm^2\")\n",
    "plt.ylabel(u\"real predict current A/cm^2\")\n",
    "plt.savefig('%s CurrentRegression.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "name_list=list(X_test)\n",
    "plt.bar(range(len(ada_model.feature_importances_)), ada_model.feature_importances_,edgecolor='black',tick_label=name_list)\n",
    "plt.xticks(rotation=90)\n",
    "plt.savefig('%s FeatureImportance.jpg' %algorithm_name,bbox_inches = 'tight')\n",
    "plt.show()\n",
    "print(ada_model.feature_importances_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
